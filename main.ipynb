{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "979b2de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import tarfile\n",
    "from torchvision.datasets.utils import download_url\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "import pandas as pd\n",
    "from torchvision.io import read_image\n",
    "\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from glob import glob\n",
    "import os\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "from torchvision.utils import save_image\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision import models\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "import datetime\n",
    "\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18bd763",
   "metadata": {},
   "source": [
    "#  DataSet Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09e443de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NYUUWData(Dataset):\n",
    "    def __init__(self, data_path, label_path, size=4500, mode='val', train_start=0, val_start=4500, test_start=5000):\n",
    "\n",
    "        self.data_path = data_path\n",
    "        self.label_path = pd.read_csv(os.path.join(label_path), names=['uw_images', 'cl_images', 'w_type'])\n",
    "        self.mode = mode\n",
    "        self.size = size\n",
    "        self.train_start = train_start\n",
    "        self.test_start = test_start\n",
    "        self.val_start = val_start\n",
    "        \n",
    "        if self.mode == 'train':\n",
    "            self.label_path = self.label_path[self.train_start:self.train_start+self.size]\n",
    "        #    self.label_path = shuffle(self.label_path, random_state=1)\n",
    "        #    self.label_path = self.label_path[0:8]\n",
    "        elif self.mode == 'test':\n",
    "            self.label_path = self.label_path[self.test_start:self.test_start+self.size]\n",
    "        elif self.mode == 'val':\n",
    "            self.label_path = self.label_path[self.val_start:self.val_start+self.size]\n",
    "        (self.label_path).reset_index(inplace = True)\n",
    "        \n",
    "        self.transform = transforms.Compose([\n",
    "           transforms.ToPILImage(),\n",
    "           transforms.Resize(size = (270, 360)),\n",
    "           transforms.CenterCrop((256, 256)),\n",
    "           transforms.ToTensor()\n",
    "        ])\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.label_path)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.data_path, self.label_path['uw_images'][idx])\n",
    "        uw_images = read_image(img_path)\n",
    "\n",
    "        label_path = os.path.join(self.data_path, self.label_path['cl_images'][idx])\n",
    "        cl_images = read_image(label_path)\n",
    "        \n",
    "        water_type = int(self.label_path['w_type'][idx])\n",
    "\n",
    "        name = os.path.basename(self.label_path['uw_images'][idx])[:-4]\n",
    "    \n",
    "        if self.transform is not None:\n",
    "            uw_images = self.transform(uw_images)\n",
    "            cl_images = self.transform(cl_images)\n",
    "            \n",
    "        return uw_images, cl_images, water_type, name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0a85f0",
   "metadata": {},
   "source": [
    "## convert to image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84bc4656",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_img(x):\n",
    "    x = 0.5 * (x + 1)\n",
    "    x = x.clamp(0, 1)\n",
    "    x = x.view(x.size(0), 3, 256, 256)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecdda7de",
   "metadata": {},
   "source": [
    "## Convert Requirement Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3c4970f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_requires_grad(nets, requires_grad=False):\n",
    "    if not isinstance(nets, list):\n",
    "        nets = [nets]\n",
    "    for net in nets:\n",
    "        if net is not None:\n",
    "            for param in net.parameters():\n",
    "                param.requires_grad = requires_grad\n",
    "\n",
    "    return requires_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8118e48",
   "metadata": {},
   "source": [
    "## Compute\n",
    "\n",
    "MSE, SSIM, PSNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba610cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_val_metrics(fE, fI, fN, dataloader, no_adv_loss):\n",
    "    \"\"\"\n",
    "        Compute SSIM, PSNR scores for the validation set\n",
    "    \"\"\"\n",
    "\n",
    "    fE.eval()\n",
    "    fI.eval()\n",
    "    fN.eval()\n",
    "\n",
    "    mse_scores = []\n",
    "    ssim_scores = []\n",
    "    psnr_scores = []\n",
    "    corr = 0\n",
    "\n",
    "    criterion_MSE = nn.MSELoss().cuda()\n",
    "\n",
    "    for idx, data in tqdm(enumerate(dataloader)):\n",
    "        uw_img, cl_img, water_type, _ = data\n",
    "        uw_img = Variable(uw_img).cuda()\n",
    "        cl_img = Variable(cl_img, requires_grad=False).cuda()\n",
    "\n",
    "        fE_out, enc_outs = fE(uw_img)\n",
    "        fI_out = to_img(fI(fE_out, enc_outs))\n",
    "        fN_out = F.softmax(fN(fE_out), dim=1)\n",
    "\n",
    "        if int(fN_out.max(1)[1].item()) == int(water_type.item()):\n",
    "            corr += 1\n",
    "\n",
    "        mse_scores.append(criterion_MSE(fI_out, cl_img).item())\n",
    "\n",
    "        fI_out = (fI_out * 255).squeeze(0).cpu().data.numpy().transpose(1, 2, 0).astype(np.uint8)\n",
    "        cl_img = (cl_img * 255).squeeze(0).cpu().data.numpy().transpose(1, 2, 0).astype(np.uint8)\n",
    "\n",
    "        ssim_scores.append(ssim(fI_out, cl_img, channel_axis = -1))\n",
    "        psnr_scores.append(psnr(cl_img, fI_out))\n",
    "\n",
    "    fE.train()\n",
    "    fI.train()\n",
    "    if not no_adv_loss:\n",
    "        fN.train()\n",
    "\n",
    "    return sum(ssim_scores)/len(dataloader), sum(psnr_scores)/len(dataloader), sum(mse_scores)/len(dataloader), corr/len(dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed0a0f6",
   "metadata": {},
   "source": [
    "## LOSSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90c1248b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adversarial loss\n",
    "\n",
    "def backward_adv_loss(fN, fE_out, water_type, lambda_adv_loss, num_classes, neg_entropy):\n",
    "    \"\"\"\n",
    "        Backpropagate the adversarial loss\n",
    "    \"\"\"\n",
    "\n",
    "    fN_out = fN(fE_out)\n",
    "    adv_loss = calc_adv_loss(fN_out, num_classes, neg_entropy) * lambda_adv_loss\n",
    "\n",
    "    adv_loss.backward()\n",
    "\n",
    "    return adv_loss\n",
    "\n",
    "def calc_adv_loss(fN_out, num_classes, neg_entropy):\n",
    "    \"\"\"\n",
    "        Calculate the adversarial loss (negative entropy or cross entropy with uniform distribution)\n",
    "    \"\"\"\n",
    "\n",
    "    if neg_entropy:\n",
    "        fN_out_softmax = F.softmax(fN_out, dim=1)\n",
    "        return torch.mean(torch.sum(fN_out_softmax * torch.log(torch.clamp(fN_out_softmax, min=1e-10, max=1.0)), 1))\n",
    "    else:\n",
    "        fN_out_log_softmax = F.log_softmax(fN_out, dim=1)\n",
    "        return -torch.mean(torch.div(torch.sum(fN_out_log_softmax, 1), num_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3a19a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new reconstruction loss\n",
    "\n",
    "class VGG19_PercepLoss(nn.Module):\n",
    "    \"\"\" Calculates perceptual loss in vgg19 space\n",
    "    \"\"\"\n",
    "    def __init__(self, _pretrained_=True):\n",
    "        super(VGG19_PercepLoss, self).__init__()\n",
    "        self.vgg = models.vgg19(pretrained=_pretrained_).features\n",
    "        for param in self.vgg.parameters():\n",
    "            param.requires_grad_(False)\n",
    "\n",
    "    def get_features(self, image, layers=None):\n",
    "        if layers is None: \n",
    "            layers = {'30': 'conv5_2'} # may add other layers\n",
    "        features = {}\n",
    "        x = image\n",
    "        for name, layer in self.vgg._modules.items():\n",
    "            x = layer(x)\n",
    "            if name in layers:\n",
    "                features[layers[name]] = x\n",
    "        return features\n",
    "\n",
    "    def forward(self, pred, true, layer='conv5_2'):\n",
    "        true_f = self.get_features(true)\n",
    "        pred_f = self.get_features(pred)\n",
    "        return torch.mean((true_f[layer]-pred_f[layer])**2)\n",
    "    \n",
    "\n",
    "def back_I_loss(fI, fE_out, enc_outs, uw_img, cl_img, criterion_MSE, optimizer_fI, retain_graph):\n",
    "    \n",
    "    ######### New Defind some Loss ##########\n",
    "    Adv_cGAN = torch.nn.MSELoss().cuda()\n",
    "    L1_G  = torch.nn.L1Loss().cuda() # similarity loss (l1)\n",
    "    L_vgg = VGG19_PercepLoss().cuda() # content loss (vgg)\n",
    "    lambda_1, lambda_con = 7, 3 # 7:3 (as in paper)\n",
    "    #########################################\n",
    "    \n",
    "    fI_out = to_img(fI(fE_out, enc_outs))\n",
    "    \n",
    "    loss_GAN =  Adv_cGAN(fI_out, uw_img)\n",
    "    loss_1 = L1_G(fI_out, cl_img) # similarity loss\n",
    "    loss_con = L_vgg(fI_out, cl_img)# content loss\n",
    "    \n",
    "    I_loss = loss_GAN + lambda_1 * loss_1  + lambda_con * loss_con \n",
    "    \n",
    "    optimizer_fI.zero_grad()\n",
    "    I_loss.backward(retain_graph=retain_graph)\n",
    "    optimizer_fI.step()\n",
    "\n",
    "    return fI_out,  I_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "410d4810",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Focal loss\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=1, gamma=2, reduction='mean'):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        ce_loss = F.cross_entropy(inputs, targets, reduction='none')\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        focal_loss = self.alpha * (1 - pt) ** self.gamma * ce_loss\n",
    "        if self.reduction == 'mean':\n",
    "            return torch.mean(focal_loss)\n",
    "        elif self.reduction == 'sum':\n",
    "            return torch.sum(focal_loss)\n",
    "        else:\n",
    "            return focal_loss\n",
    "\n",
    "        \n",
    "def new_back_N(fN, fE_out, num_classes, actual_target, criterion_CE, optimizer_fN):\n",
    "    \n",
    "    ## Focal loss\n",
    "    criterion_focal = FocalLoss(alpha=1, gamma=2).cuda()\n",
    "    \n",
    "    #----------- water target -----\n",
    "    tar = np.arange(num_classes)\n",
    "    mapping = {}\n",
    "    for x in range(len(tar)): mapping[tar[x]] = x\n",
    "    target = []\n",
    "    for c in actual_target:\n",
    "      x = c.item()\n",
    "      arr = list(np.zeros(len(tar), dtype = int))\n",
    "      arr[mapping[x]] = 1\n",
    "      target.append(arr)\n",
    "    #-----------------------------\n",
    "    target = torch.FloatTensor(target).cuda()\n",
    "    \n",
    "    \n",
    "    fN_out = fN(fE_out.detach())\n",
    "    \n",
    "    N_loss = criterion_focal(fN_out, target)\n",
    "    \n",
    "    N_loss.backward()\n",
    "\n",
    "    return N_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d0155a",
   "metadata": {},
   "source": [
    "## Log files   #Save Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d816824",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_log(log_file_path, status):\n",
    "    \"\"\"\n",
    "        Write to the log file\n",
    "    \"\"\"\n",
    "    with open(log_file_path, \"a\") as log_file:\n",
    "        log_file.write(status+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704752af",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a61a07bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class double_conv(nn.Module):\n",
    "    '''(conv => BN => ReLU) * 2'''\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(double_conv, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_ch, out_ch, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class inconv(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(inconv, self).__init__()\n",
    "        self.conv = double_conv(in_ch, out_ch)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class down(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(down, self).__init__()\n",
    "        self.mpconv = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            double_conv(in_ch, out_ch)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.mpconv(x)\n",
    "        return x\n",
    "\n",
    "class up(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, bilinear=True):\n",
    "        super(up, self).__init__()\n",
    "        if bilinear:\n",
    "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        else:\n",
    "            self.up = nn.ConvTranspose2d(in_ch//2, in_ch//2, 2, stride=2)\n",
    "\n",
    "        self.conv = double_conv(in_ch, out_ch)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        \n",
    "        # input is CHW\n",
    "        diffY = x2.size()[2] - x1.size()[2]\n",
    "        diffX = x2.size()[3] - x1.size()[3]\n",
    "\n",
    "        x1 = F.pad(x1, (diffX // 2, diffX - diffX//2, diffY // 2, diffY - diffY//2))\n",
    "\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "class outconv(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(outconv, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_ch, out_ch, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return input.view(input.size(0), -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19c2645b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder\n",
    "class UNetEncoder(nn.Module):\n",
    "    def __init__(self, n_channels=3):\n",
    "        super(UNetEncoder, self).__init__()\n",
    "        self.inc = inconv(n_channels, 64)\n",
    "        self.down1 = down(64, 128)\n",
    "        self.down2 = down(128, 256)\n",
    "        self.down3 = down(256, 512)\n",
    "        self.down4 = down(512, 512)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "\n",
    "        return x5, (x1, x2, x3, x4)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb8e1166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder\n",
    "\n",
    "class UNetDecoder(nn.Module):\n",
    "    def __init__(self, n_channels=3):\n",
    "        super(UNetDecoder, self).__init__()\n",
    "        self.up1 = up(1024, 256)\n",
    "        self.up2 = up(512, 128)\n",
    "        self.up3 = up(256, 64)\n",
    "        self.up4 = up(128, 64)\n",
    "        self.outc = outconv(64, n_channels)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x, enc_outs):\n",
    "        x = self.sigmoid(x)\n",
    "        x = self.up1(x, enc_outs[3])\n",
    "        x = self.up2(x, enc_outs[2])\n",
    "        x = self.up3(x, enc_outs[1])\n",
    "        x = self.up4(x, enc_outs[0])\n",
    "        x = self.outc(x)\n",
    "        return nn.Tanh()(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a5c4acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifier\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Conv2d(512, 256, 4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "            Flatten(),\n",
    "            nn.Linear(4096, 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(1024, num_classes)\n",
    "            )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.classifier(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc84e89a",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ee0a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    # Define data path and label path\n",
    "    data_path = './data/'\n",
    "    label_path = './data/label.csv'\n",
    "    \n",
    "    train_size = 4500\n",
    "    val_size = 500\n",
    "    test_size = 340\n",
    "\n",
    "    batch_size = 4\n",
    "    learning_rate = 1e-3\n",
    "    start_epoch = 1\n",
    "    end_epoch = 201\n",
    "\n",
    "    num_classes = 6\n",
    "    num_channels = 3\n",
    "    save_interval = 5\n",
    "    \n",
    "    lambda_adv_loss = 1\n",
    "    \n",
    "    name = 'Checkpoints_values'\n",
    "    \n",
    "    continue_train = False\n",
    "    neg_entropy = True\n",
    "    no_adv_loss = False\n",
    "    \n",
    "    \n",
    "    train_dataset = NYUUWData(data_path, label_path, size=train_size,train_start=0, mode='train')\n",
    "    val_dataset = NYUUWData(data_path, label_path, size=val_size,val_start=4500, mode='val')\n",
    "    test_dataset = NYUUWData(data_path, label_path, size=test_size,test_start=5000, mode='test')\n",
    "\n",
    "    train_dataloader= DataLoader(train_dataset, batch_size=4, shuffle=False)\n",
    "    val_dataloader= DataLoader(val_dataset, batch_size=1, shuffle=True)\n",
    "    test_dataloader= DataLoader(test_dataset, batch_size=1, shuffle=True)\n",
    "    \n",
    "    fN = Classifier(num_classes).cuda()\n",
    "    fN_req_grad = True\n",
    "    fN.train()\n",
    "    criterion_CE = nn.CrossEntropyLoss().cuda()\n",
    "    optimizer_fN = torch.optim.Adam(fN.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "    \n",
    "    \n",
    "    \n",
    "    fE = UNetEncoder(num_channels).cuda()\n",
    "    fI = UNetDecoder(num_channels).cuda()\n",
    "\n",
    "    criterion_MSE = nn.MSELoss().cuda()\n",
    "\n",
    "    optimizer_fE = torch.optim.Adam(fE.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "    optimizer_fI = torch.optim.Adam(fI.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "\n",
    "    fE.train()\n",
    "    fI.train()\n",
    "    \n",
    "    # IF want to use pre trained model or want to continue training\n",
    "    \n",
    "   \n",
    "    if continue_train:\n",
    "        \"\"\"\n",
    "            Load pretrained models to continue training\n",
    "        \"\"\"\n",
    "        \n",
    "        # path of checkpoints\n",
    "        fE_load_path = './checkpoints/unet_adv/fE_86.pth'  \n",
    "        fI_load_path = './checkpoints/unet_adv/fI_86.pth'\n",
    "        fN_load_path = './checkpoints/unet_adv/fN_86.pth'\n",
    "\n",
    "        if fE_load_path:\n",
    "            fE.load_state_dict(torch.load(fE_load_path))\n",
    "            print ('Loaded fE from {}'.format(fE_load_path))\n",
    "        if fI_load_path:\n",
    "            fI.load_state_dict(torch.load(fI_load_path))\n",
    "            print ('Loaded fI from {}'.format(fI_load_path))\n",
    "        if not no_adv_loss and fN_load_path:\n",
    "            fN.load_state_dict(torch.load(fN_load_path))\n",
    "            print ('Loaded fN from {}'.format(fN_load_path))\n",
    "            \n",
    "            \n",
    "    ## Create checkpoint folder to store files \n",
    "    if not os.path.exists('./checkpoints/{}'.format(name)):\n",
    "        os.mkdir('./checkpoints/{}'.format(name))\n",
    "\n",
    "    log_file_path = './checkpoints/{}/log_file.txt'.format(name)\n",
    "\n",
    "    now = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M\")\n",
    "\n",
    "    status = '\\nTRAINING SESSION STARTED ON {}\\n'.format(now)\n",
    "    write_to_log(log_file_path, status)\n",
    "    \n",
    "    if continue_train and not no_adv_loss:\n",
    "        fI_val_ssim, _, _, fN_val_acc = compute_val_metrics(fE, fI, fN, val_dataloader, no_adv_loss)\n",
    "    else:\n",
    "        fI_val_ssim = -1\n",
    "        fN_val_acc = -1\n",
    "        \n",
    "    \n",
    "    print(\"Encoder SSIM value = {}, Decoder Acc = {}\".format(fI_val_ssim, fN_val_acc))\n",
    "    \n",
    "    i = 1\n",
    "    \n",
    "    for epoch in range(start_epoch, end_epoch):\n",
    "        \"\"\"\n",
    "            Main training loop\n",
    "        \"\"\"\n",
    "\n",
    "        if not no_adv_loss:\n",
    "            \"\"\"\n",
    "                Print the current cross-validation scores\n",
    "            \"\"\"\n",
    "\n",
    "            status = 'Avg fI val SSIM: {}, Avg fN val acc: {}'.format(fI_val_ssim, fN_val_acc)\n",
    "            print (status)\n",
    "            write_to_log(log_file_path, status)\n",
    "\n",
    "        for idx, data in tqdm(enumerate(train_dataloader)):\n",
    "            uw_img, cl_img, water_type, _ = data\n",
    "            uw_img = Variable(uw_img).cuda()\n",
    "            cl_img = Variable(cl_img, requires_grad=False).cuda()\n",
    "            actual_target = Variable(water_type, requires_grad=False).cuda()\n",
    "\n",
    "            fE_out, enc_outs = fE(uw_img)\n",
    "\n",
    "            if i <= 10:\n",
    "                \"\"\"\n",
    "                    Train the encoder-decoder only\n",
    "                \"\"\"\n",
    "\n",
    "                optimizer_fE.zero_grad()\n",
    "                fI_out, I_loss = back_I_loss(fI, fE_out, enc_outs, uw_img, cl_img, criterion_MSE, optimizer_fI,  retain_graph=not no_adv_loss)\n",
    "\n",
    "                if not no_adv_loss:\n",
    "                    if fN_req_grad:\n",
    "                        fN_req_grad = set_requires_grad(fN, requires_grad=False)\n",
    "                    adv_loss = backward_adv_loss(fN, fE_out, water_type, lambda_adv_loss, num_classes, neg_entropy)\n",
    "                    progress = \"\\tEpoch: {}\\tIter: {}\\tI_loss: {}\\tadv_loss: {}\".format(epoch, idx, I_loss.item(), adv_loss.item())\n",
    "                else:\n",
    "                    progress = \"\\tEpoch: {}\\tIter: {}\\tI_loss: {}\".format(epoch, idx, I_loss.item())\n",
    "\n",
    "                optimizer_fE.step()\n",
    "\n",
    "                if idx % 50 == 0:\n",
    "                    save_image(uw_img.cpu().data, './results/uw_img.png')\n",
    "                    save_image(fI_out.cpu().data, './results/fI_out.png')\n",
    "                    save_image(cl_img.cpu().data, './results/cl_img.png')\n",
    "                \n",
    "                \n",
    "            elif i <= 20:\n",
    "                \"\"\"\n",
    "                    Train the nusiance classifier only\n",
    "                \"\"\"\n",
    "\n",
    "                if not fN_req_grad:\n",
    "                    fN_req_grad = set_requires_grad(fN, requires_grad=True)\n",
    "                    \n",
    "                    N_loss = new_back_N_Focal(fN, fE_out, num_classes, actual_target, criterion_CE, optimizer_fN)\n",
    "                progress = \"\\tEpoch: {}\\tIter: {}\\tN_loss: {}\".format(epoch, idx, N_loss.item())\n",
    "                \n",
    "\n",
    "            else:\n",
    "                \"\"\"\n",
    "                    Train the encoder-decoder only\n",
    "                \"\"\"\n",
    "\n",
    "                optimizer_fE.zero_grad()\n",
    "                fI_out, I_loss = back_I_loss(fI, fE_out, enc_outs, uw_img, cl_img, criterion_MSE, optimizer_fI,  retain_graph=not no_adv_loss)\n",
    "\n",
    "                if not no_adv_loss:\n",
    "                    if fN_req_grad:\n",
    "                        fN_req_grad = set_requires_grad(fN, requires_grad=False)\n",
    "                    adv_loss = backward_adv_loss(fN, fE_out, water_type, lambda_adv_loss, num_classes, neg_entropy)\n",
    "\n",
    "                    progress = \"\\tEpoch: {}\\tIter: {}\\tI_loss: {}\\tadv_loss: {}\".format(epoch, idx, I_loss.item(), adv_loss.item())\n",
    "\n",
    "                else:\n",
    "                    progress = \"\\tEpoch: {}\\tIter: {}\\tI_loss: {}\".format(epoch, idx, I_loss.item())\n",
    "\n",
    "                optimizer_fE.step()\n",
    "\n",
    "                if idx % 50 == 0:\n",
    "                    save_image(uw_img.cpu().data, './results/uw_img.png')\n",
    "                    save_image(fI_out.cpu().data, './results/fI_out.png')\n",
    "                    save_image(cl_img.cpu().data, './results/cl_img.png')\n",
    "                \n",
    "                \n",
    "            if idx % 50 == 0:\n",
    "                print (progress)\n",
    "                write_to_log(log_file_path, progress)\n",
    "            \n",
    "        if i >= 30:\n",
    "            i = 1\n",
    "        else :\n",
    "            i = i+1\n",
    "\n",
    "        # Save models\n",
    "        torch.save(fE.state_dict(), './checkpoints/{}/fE_latest.pth'.format(name))\n",
    "        torch.save(fI.state_dict(), './checkpoints/{}/fI_latest.pth'.format(name))\n",
    "        if not no_adv_loss:\n",
    "            torch.save(fN.state_dict(), './checkpoints/{}/fN_latest.pth'.format(name))\n",
    "\n",
    "        if epoch % save_interval == 0:\n",
    "            torch.save(fE.state_dict(), './checkpoints/{}/fE_{}.pth'.format(name, epoch))\n",
    "            torch.save(fI.state_dict(), './checkpoints/{}/fI_{}.pth'.format(name, epoch))\n",
    "            if not no_adv_loss:\n",
    "                torch.save(fN.state_dict(), './checkpoints/{}/fN_{}.pth'.format(name, epoch))\n",
    "\n",
    "        status = 'End of epoch. Models saved.'\n",
    "        print (status)\n",
    "        write_to_log(log_file_path, status)\n",
    "\n",
    "        if not no_adv_loss:\n",
    "            \"\"\"\n",
    "                Compute the cross validation scores after the epoch\n",
    "            \"\"\"\n",
    "            fI_val_ssim, _, _, fN_val_acc = compute_val_metrics(fE, fI, fN, val_dataloader, no_adv_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da6aabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__== \"__main__\":\n",
    "    if not os.path.exists('./results'):\n",
    "        os.mkdir('./results')\n",
    "    if not os.path.exists('./checkpoints'):\n",
    "        os.mkdir('./checkpoints')\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39bd67db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
